{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM - Kernel\n",
    "\n",
    "* Potentielle Kernel: RBF, Polynomial, Spectral Mixture Kernel, Sigmoid Kernel\n",
    "* Calculate SVM using dual decision functions\n",
    "* Thus: Model theta has as many parameters as examples.\n",
    "* Kernel function: Measure of similarity between instances.\n",
    "* Hence: How similar is instance x to each other trainings instance?\n",
    "* Derivation from the primal into the dual form is necessary (lecture).\n",
    "\n",
    "Optimization criterion of the dual SVM:\n",
    "\n",
    "$$\n",
    "max_{\\beta} \\sum_{i=1}^n \\beta_i - \\frac{1}{2} \\sum_{i,j=1}^n \\beta_i \\beta_j y_i y_j k(x_i,x_j) \\text{, such that } 0 \\leq \\beta_i \\leq \\lambda\n",
    "$$\n",
    "\n",
    "* Optimization over parameters beta\n",
    "* Sparse solution (solution of a problem where most of the elements are zero)\n",
    "* Reason: Samples only appear as pairwise inner products.\n",
    "* Sparsity desired property because it often leads to simpler, more interpretable models.\n",
    "* QPP - Quadratic programming problem\n",
    "\n",
    "Dual from of the decision function:\n",
    "\n",
    "$$\n",
    "f_{\\beta}(x)= \\sum_{x_i\\in SV} \\beta_i y_i k(x_i, x)\n",
    "$$\n",
    "\n",
    "(SV = Support Vectors)\n",
    "\n",
    "* Only the support vectors (points with non-zero beta_i) contribute to the decision function.\n",
    "* Decision function is weighted sum over the support vectors.\n",
    "* Decides the class based on the sign of this sum.\n",
    "\n",
    "\n",
    "**Hint:**\n",
    "\n",
    "This code is a implementation of kernelized empirical risk minimization that aligns with the SVM concepts but uses gradient descent instead of directly solving the dual problem via quadratic programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking path: /Users/marleenstreicher/Documents/git/IDA_Laser/IDA_Laser/data_split_indices.pkl\n",
      "Path exists: True\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from svm_helper import SvmHelper\n",
    "from dataset import BaseDataset\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "file_path = \"../../data/laser.mat\"\n",
    "mat_dict = loadmat(file_path)\n",
    "\n",
    "dataset = BaseDataset(mat_dict, \"X\", \"Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTW Kernel\n",
    "\n",
    "DTW = Dynamic Time Warping - A way to measure the similarity between two sequences, which vary in length or be misaligned in time.\n",
    "\n",
    "Given a metric $d: X \\times X \\rightarrow \\mathbb{R}_{\\geq 0}$ on the input space $X$, the family of *DTW Kernels* is given as:\n",
    "\n",
    "$$ k_{\\text{DTW}}(x, x') = e^{- \\lambda d_{\\text{DTW}}(x, x'; d)}, $$\n",
    "\n",
    "* Distance measure $d_{DTW}$ is heart of DTW and is computed by a recursive function $\\gamma(i, j)$.\n",
    "* $\\gamma(i, j)$ builds up the minimal distance between the sequences uop to position i,j.\n",
    "* Computation of DTW distance: Dynamic programming with a $(|x|+1) \\times (|x'|+1)$ grid.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "$$\n",
    "d_{DTW}(x,x´;d) = \\gamma(\\mid x\\mid,\\mid x´\\mid )\n",
    "$$\n",
    "\n",
    "$$ \n",
    "\\gamma(i, j) = \\begin{cases} d(x_i, x_j') + \\min\\left(\\gamma(i-1, j-1), \\gamma(i-1, j), \\gamma(i, j-1)\\right) & (1 \\leq i \\leq |x|, \\, 1 \\leq j \\leq |x'|), \\\\ \n",
    "\\infty & i = 0 \\vee j = 0, \\\\\n",
    "0 & (i, j) = (0, 0). \\end{cases}\n",
    "$$\n",
    "\n",
    "* $\\gamma(i, j)$ is calculated all possible combinations of $j$ and $i$, starting from $\\gamma(0, 0)$ up to $\\gamma(\\mid x\\mid,\\mid x´\\mid )$\n",
    "\n",
    "Table:\n",
    "\n",
    "|     | 0   | 2   | 4   | 6   |\n",
    "|-----|-----|-----|-----|-----|\n",
    "| 0   | 0   | ∞   | ∞   | ∞   |\n",
    "| 1   | ∞   | 1   | 9   | 25  |\n",
    "| 3   | ∞   | 2   | 2   | 14  |\n",
    "| 4   | ∞   | 5   | 2   | 8   |\n",
    "\n",
    "\n",
    "$$ \\gamma(1, 1) = (1 - 2)^2 + \\min(\\gamma(0, 0), \\gamma(0, 1), \\gamma(1, 0)) = 1 + 0 = 1 $$\n",
    "$$\\gamma(2, 2) = (3 - 4)^2 + \\min(\\gamma(1, 1), \\gamma(1, 2), \\gamma(2, 1)) = 1 + 1 = 2 $$\n",
    "\n",
    "The final DTW distance is:\n",
    "\n",
    "$$\n",
    "\\gamma(3, 3) = 8\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"../../images/DTW_dynamic_programming.png\" alt=\"Image\" style=\"width:30%\">\n",
    "\n",
    "Figure A: Example of a DTW $\\gamma(i, j)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'epsilon': [1e-4, 1e-5, 1e-6],\n",
    "    'alpha_0': [0.001, 0.01, 0.1, 1],\n",
    "    'lambda_value': [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "def dtw_kernel(seq1, seq2):\n",
    "    return np.exp(-SvmHelper.d_DTW(seq1, seq2, SvmHelper.calculate_euclidean_distance))\n",
    "\n",
    "def train_model_with_params(params, verbose = False):\n",
    "    theta = SvmHelper.regularised_kernel_erm_batch(dataset.train_inputs, dataset.train_labels,\n",
    "                                                            kernel_function=dtw_kernel, \n",
    "                                                            max_iterations=100,\n",
    "                                                            epsilon=params['epsilon'], \n",
    "                                                            alpha=params['alpha_0'], \n",
    "                                                            lbda=params['lambda_value'])\n",
    "    \n",
    "    if theta is None:\n",
    "        return -float('inf')\n",
    "\n",
    "    predictions = SvmHelper.predict_kernel(theta=theta, kernel_function=dtw_kernel, test_inputs=dataset.test_inputs, train_inputs=dataset.train_inputs)\n",
    "\n",
    "    if predictions is None:\n",
    "        return -float('inf') \n",
    "    \n",
    "    accuracy = accuracy_score(dataset.test_labels, predictions)\n",
    "\n",
    "    if verbose == True:\n",
    "        print(f\"Accuracy with current params: {accuracy}\")\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "best_params = None\n",
    "best_score = 0.0  \n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    score = train_model_with_params(params)\n",
    "    if score > best_score: \n",
    "        best_score = score\n",
    "        best_params = params\n",
    "\n",
    "print(\"Best parameters found:\", best_params)\n",
    "print(\"Best score:\", best_score)\n",
    "\n",
    "os.system('say \"Param search endet\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = SvmHelper.regularised_kernel_erm_batch(\n",
    "    inputs=dataset.train_inputs,\n",
    "    labels=dataset.train_labels,\n",
    "    kernel_function=dtw_kernel, \n",
    "    max_iterations=200,\n",
    "    alpha=best_params['alpha_0'], \n",
    "    epsilon=best_params['epsilon'], \n",
    "    lbda=best_params['lambda_value']  \n",
    "    verbose=False,\n",
    "    figure=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envPython3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
